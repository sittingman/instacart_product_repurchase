{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pycaret.classification import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# aisles = pd.read_csv('./data/aisles.csv')\n",
    "# dept = pd.read_csv('./data/departments.csv')\n",
    "orders = pd.read_csv('./data/orders.csv')\n",
    "products = pd.read_csv('./data/products.csv')\n",
    "orders_p = pd.read_csv('./data/order_products__prior.csv')\n",
    "orders_tr = pd.read_csv('./data/order_products__train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_products(x):\n",
    "    \"\"\" Join the prediced reordered items into one line per order\n",
    "    \n",
    "    Args:\n",
    "        x: items that will be reordered\n",
    "    \n",
    "    Returns:\n",
    "        a string that have all reordered items into one line per order id\"\"\"\n",
    "    return \" \".join(list(x.astype('str')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#path to save the prediction\n",
    "path='./data/submit/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline (using last order per user)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "orders['last_order'] = orders['order_id'].shift(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "prior_order = orders.query('eval_set == \"prior\"')\n",
    "train_order = orders.query('eval_set == \"train\"')\n",
    "test_order = orders.query('eval_set == \"test\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline = pd.merge(test_order, orders_p, left_on='last_order', right_on='order_id', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_df = baseline[['order_id_x','product_id']]\n",
    "baseline_df = baseline_df.groupby(['order_id_x'])['product_id'].aggregate(merge_products).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(75000, 2)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseline_df.columns = ['order_id','products']\n",
    "baseline_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_df.to_csv(path+'base_model.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_submit = pd.read_csv('./data/df_submit.csv')\n",
    "load = './data/save_model/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def submit_data(model_name, dataset, prob):\n",
    "    \"\"\" step on loading saved models and creating the data submission to Kaggle competition\n",
    "    \n",
    "    Args:\n",
    "        model_name: trained model from machine learning section\n",
    "        dataset: test dataset\n",
    "        prob: probability threshold to determine whether the prediction is 0 or 1\n",
    "        \n",
    "    Returns:\n",
    "        df: dataframe that match Kaggle sumbission requirement\n",
    "    \"\"\"\n",
    "    model = load_model(load+model_name)\n",
    "    pred = predict_model(model, data=dataset, probability_threshold=prob)\n",
    "    pred.index = dataset.index    \n",
    "    submit = pred.loc[pred['Label']==1].reset_index()\n",
    "    submit['product_id'] = submit['product_id'].astype('str')\n",
    "    df = pd.merge(test_order[['order_id', 'user_id']], submit, on=['user_id'], how='left').fillna(0)\n",
    "    df= df.groupby(['order_id'])['product_id'].aggregate(merge_products).reset_index()\n",
    "    df.columns = ['order_id','products']\n",
    "    print(df.shape)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dt = load_model('./data/dt')\n",
    "# submit_data(dt, df_submit).to_csv('./data/dt.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Random Forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(75000, 2)\n"
     ]
    }
   ],
   "source": [
    "submit_data('rfc', df_submit, .25).to_csv(path+'rfc.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Light Gradient Boosting "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(75000, 2)\n"
     ]
    }
   ],
   "source": [
    "submit_data('lgbm', df_submit, .25).to_csv(path+'lightgbm.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(75000, 2)\n"
     ]
    }
   ],
   "source": [
    "submit_data('gbc', df_submit, .25).to_csv(path+'gbc.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(75000, 2)\n"
     ]
    }
   ],
   "source": [
    "submit_data('lr', df_submit, .25).to_csv(path+'lr.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### XgBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(75000, 2)\n"
     ]
    }
   ],
   "source": [
    "submit_data('xgb', df_submit, .25).to_csv(path+'xgb.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
